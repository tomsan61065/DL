{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5]\n",
      " [4.9 3. ]\n",
      " [4.7 3.2]\n",
      " [4.6 3.1]\n",
      " [5.  3.6]\n",
      " [5.4 3.9]\n",
      " [4.6 3.4]\n",
      " [5.  3.4]\n",
      " [4.4 2.9]\n",
      " [4.9 3.1]\n",
      " [5.4 3.7]\n",
      " [4.8 3.4]\n",
      " [4.8 3. ]\n",
      " [4.3 3. ]\n",
      " [5.8 4. ]\n",
      " [5.7 4.4]\n",
      " [5.4 3.9]\n",
      " [5.1 3.5]\n",
      " [5.7 3.8]\n",
      " [5.1 3.8]\n",
      " [5.4 3.4]\n",
      " [5.1 3.7]\n",
      " [4.6 3.6]\n",
      " [5.1 3.3]\n",
      " [4.8 3.4]\n",
      " [5.  3. ]\n",
      " [5.  3.4]\n",
      " [5.2 3.5]\n",
      " [5.2 3.4]\n",
      " [4.7 3.2]\n",
      " [4.8 3.1]\n",
      " [5.4 3.4]\n",
      " [5.2 4.1]\n",
      " [5.5 4.2]\n",
      " [4.9 3.1]\n",
      " [7.  3.2]\n",
      " [6.4 3.2]\n",
      " [6.9 3.1]\n",
      " [5.5 2.3]\n",
      " [6.5 2.8]\n",
      " [5.7 2.8]\n",
      " [6.3 3.3]\n",
      " [4.9 2.4]\n",
      " [6.6 2.9]\n",
      " [5.2 2.7]\n",
      " [5.  2. ]\n",
      " [5.9 3. ]\n",
      " [6.  2.2]\n",
      " [6.1 2.9]\n",
      " [5.6 2.9]\n",
      " [6.7 3.1]\n",
      " [5.6 3. ]\n",
      " [5.8 2.7]\n",
      " [6.2 2.2]\n",
      " [5.6 2.5]\n",
      " [5.9 3.2]\n",
      " [6.1 2.8]\n",
      " [6.3 2.5]\n",
      " [6.1 2.8]\n",
      " [6.4 2.9]\n",
      " [6.6 3. ]\n",
      " [6.8 2.8]\n",
      " [6.7 3. ]\n",
      " [6.  2.9]\n",
      " [5.7 2.6]\n",
      " [5.5 2.4]\n",
      " [5.5 2.4]\n",
      " [5.8 2.7]\n",
      " [6.  2.7]\n",
      " [5.4 3. ]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd #for csv\n",
    "import scipy.io as sio\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load the information in the file in a format that python can interpret\n",
    "matTrainData = sio.loadmat(\"train.mat\")\n",
    "matTestData = sio.loadmat(\"test.mat\")\n",
    "#print(matData)\n",
    "#print(matTrainData.items()) # 得知有哪些 items\n",
    "\n",
    "#如何 element wise concate\n",
    "#https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html\n",
    "trainDataX = np.concatenate((np.array(matTrainData[\"x1\"]), np.array(matTrainData[\"x2\"])), axis=1 )\n",
    "print(trainDataX)\n",
    "trainDataY = np.concatenate(np.array(matTrainData[\"y\"]))\n",
    "print(trainDataY)\n",
    "\n",
    "testX = np.concatenate((np.array(matTestData[\"x1\"]), np.array(matTestData[\"x2\"])), axis=1 )\n",
    "testY = np.concatenate(np.array(matTestData[\"y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.85898317]\n",
      "[[-18.34633961  19.23702253]]\n",
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n",
      "[26.86807291]\n",
      "[[-13.44781941  14.40754423]]\n",
      "[16.87549674]\n",
      "[[-8.98640867 10.00480097]]\n",
      "[9.3955747]\n",
      "[[-5.42034585  6.32315196]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "percentage of misclassified test samples: 3 %\n"
     ]
    }
   ],
   "source": [
    "### Q1-5 ###\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "#logreg = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "logreg.fit(trainDataX, trainDataY)\n",
    "predictY = logreg.predict(testX)\n",
    "#print(predictY)\n",
    "#print(testY)\n",
    "print(logreg.intercept_)\n",
    "print(logreg.coef_)\n",
    "logreg = LogisticRegression(C=1e4, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(trainDataX, trainDataY)\n",
    "print(logreg.intercept_)\n",
    "print(logreg.coef_)\n",
    "logreg = LogisticRegression(C=1e3, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(trainDataX, trainDataY)\n",
    "print(logreg.intercept_)\n",
    "print(logreg.coef_)\n",
    "logreg = LogisticRegression(C=1e2, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(trainDataX, trainDataY)\n",
    "print(logreg.intercept_)\n",
    "print(logreg.coef_)\n",
    "\n",
    "count = 0\n",
    "print(testY)\n",
    "for i in range(len(predictY)):\n",
    "    if predictY[i] != testY[i]:\n",
    "        count +=1\n",
    "print(\"percentage of misclassified test samples: %d %%\" % (count/len(predictY)*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "35.0 -15.0 15.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "/home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6392.804968157981 -44108.573362587515 73835.94472907751 0.0\n",
      "6392.804968157981 -44108.573362587515 73835.94472907751 0.0\n",
      "6392.804968157981 -44108.573362587515 73835.94472907751 0.0\n",
      "6392.804968157981 -44108.573362587515 73835.94472907751 0.0\n",
      "6392.804968157981 -44108.573362587515 73835.94472907751 0.0\n",
      "6392.804968157981 -44108.573362587515 73835.94472907751 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2e6d6f92604e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#        print(1/(1 + np.exp(-θ0 -θ1*x1 - θ2*x2)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mθ0Grad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mθ0\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mθ1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mθ2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mθ1Grad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mθ0\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mθ1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mθ2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mθ2Grad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mθ0\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mθ1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mθ2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Q1-6 ###\n",
    "#P(C|x) -> P(C^x)/P(x) = h(θ) = 1/(1 + e**(-θ0 -θ1*x1 - θ2*x2) )\n",
    "\n",
    "#initial values\n",
    "θ0 = 35.0\n",
    "θ1 = -15.0\n",
    "θ2 = 15.0\n",
    "lr = 100\n",
    "iteration = 100000\n",
    "\n",
    "θ0Lr = 0.0\n",
    "θ1Lr = 0.0\n",
    "θ2Lr = 0.0\n",
    "\n",
    "θ0_history = [θ0]\n",
    "θ1_history = [θ1]\n",
    "θ2_history = [θ2]    \n",
    "\n",
    "loss = 0.0\n",
    "\n",
    "print(len(trainDataX))\n",
    "\n",
    "#print(trainDataX)\n",
    "\n",
    "for i in range(iteration):\n",
    "    θ0Grad = 0.0\n",
    "    θ1Grad = 0.0\n",
    "    θ2Grad = 0.0\n",
    "    loss = 0.0\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(θ0, θ1, θ2, loss)\n",
    "        #print(θ0Lr, θ1Lr, θ2Lr)\n",
    "    \n",
    "    #計算 gradient\n",
    "    for n in range(len( trainDataX)):\n",
    "        x1 = trainDataX[n][0]\n",
    "        x2 = trainDataX[n][1]\n",
    "        \n",
    "        #loss f\n",
    "        loss += -(trainDataY[n]* np.log( 1/(1 + np.exp(-θ0 -θ1*x1 - θ2*x2)) ) + (1 - trainDataY[n])*np.log(1 - 1/(1 + np.exp(-θ0 -θ1*x1 - θ2*x2)) ))\n",
    "        \n",
    "#        print(1/(1 + np.exp(-θ0 -θ1*x1 - θ2*x2)))\n",
    "        θ0Grad += -(trainDataY[n] - 1/(1 + np.exp(-θ0 -θ1*x1 - θ2*x2)))*1\n",
    "        θ1Grad += -(trainDataY[n] - 1/(1 + np.exp(-θ0 -θ1*x1 - θ2*x2)))*x1\n",
    "        θ2Grad += -(trainDataY[n] - 1/(1 + np.exp(-θ0 -θ1*x1 - θ2*x2)))*x2\n",
    "    \n",
    "    θ0Grad /= len(trainDataX)\n",
    "    θ1Grad /= len(trainDataX)\n",
    "    θ2Grad /= len(trainDataX)\n",
    "    \n",
    "    θ0Lr += θ0Grad ** 2\n",
    "    θ1Lr += θ1Grad ** 2\n",
    "    θ2Lr += θ2Grad ** 2\n",
    "    \n",
    "    #更新 gradient\n",
    "    θ0 = θ0 - lr * θ0Grad#/np.sqrt(θ0Lr)\n",
    "    θ1 = θ1 - lr * θ1Grad#/np.sqrt(θ1Lr)\n",
    "    θ2 = θ2 - lr * θ2Grad#/np.sqrt(θ2Lr)\n",
    "    \n",
    "    # Store parameters for plotting\n",
    "    θ0_history.append(θ0)\n",
    "    θ1_history.append(θ1)\n",
    "    θ2_history.append(θ2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.plot([-188.4], [2.67], 'x', ms=12, markeredgewidth=3, color='orange')\n",
    "plt.plot(θ1_history, θ2_history, 'o-', ms=3, lw=1.5, color='black')\n",
    "plt.xlim(-25,-15)\n",
    "plt.ylim(15,25)\n",
    "plt.xlabel(r'$θ1$', fontsize=16)\n",
    "plt.ylabel(r'$θ2$', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "print([θ0, θ1, θ2])\n",
    "\n",
    "print(testX)\n",
    "print(testY)\n",
    "predictY = 1/(np.exp(-(testX[:, 0]*θ1 + testX[:,1]*θ2 + θ0) ) + 1)\n",
    "count = 0\n",
    "for i in range(len(predictY)):\n",
    "    print(predictY[i], testY[i])\n",
    "    if predictY[i] > 0.5 and testY[i] != 1:\n",
    "        count +=1\n",
    "    elif predictY[i] < 0.5 and testY[i] != 0:\n",
    "        count +=1\n",
    "print(\"percentage of misclassified test samples: %f\" % (count/len(predictY)*100))\n",
    "\n",
    "X = testX\n",
    "Y = testY\n",
    "\n",
    "#point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

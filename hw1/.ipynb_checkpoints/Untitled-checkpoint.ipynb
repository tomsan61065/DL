{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(12)\n",
    "number_observation=5000\n",
    "#建立多元常態分佈矩陣, 而第二個list則為協方差矩陣,描述x1,x2變數間的相關關係\n",
    "x1=np.random.multivariate_normal([0,0],[[1,0.75],[0.75,1]],number_observation)\n",
    "x2=np.random.multivariate_normal([1,4],[[1,0.75],[0.75,1]],number_observation)\n",
    "#將其兩個從原本的shape都為(5000,2) 轉變成(10000,2) 疊加的概念\n",
    "simulated_separableish_features=np.vstack((x1,x2)).astype(np.float32)\n",
    "\n",
    "#為了設置color的label\n",
    "simulated_labels=np.hstack((np.zeros(number_observation),np.ones(number_observation)))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(simulated_separableish_features[:,0],simulated_separableish_features[:,1],c=simulated_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(scores):\n",
    "    return 1/(1+np.exp(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(features,target,weights):\n",
    "    scores=np.dot(features,weights)\n",
    "    l1=np.sum(target*scores-np.log(1+np.exp(scores)))\n",
    "    return l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(features,target,num_steps,learning_rate,add_intercept=False):\n",
    "    make_plot=[]\n",
    "    #代表如果是否需要截距項 True的話就會建立之\n",
    "    if add_intercept:\n",
    "        intercept=np.ones((features.shape[0],1))\n",
    "        features=np.hstack((intercept,features))\n",
    "    \n",
    "    weights=np.zeros(features.shape[1])\n",
    "    #開始進行迴圈跑最出最佳參數\n",
    "    for step in range(num_steps):\n",
    "        scores=np.dot(features,weights)\n",
    "        #function套入sigmoid function得1機率值\n",
    "        print(scores)\n",
    "        predictions=sigmoid(scores)\n",
    "        #觀看誤差\n",
    "        output_error_singal=target-predictions\n",
    "        #gradient\n",
    "        gradient=np.dot(features.T,output_error_singal)\n",
    "        weights+=learning_rate*gradient\n",
    "        \n",
    "        #print出藉由參數不斷的調整 Loss function不斷在向最小化邁進\n",
    "        if step%10000==0:\n",
    "            make_plot.append(log_likelihood(features,target,weights))\n",
    "    return weights,make_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=logistic_regression(simulated_separableish_features,simulated_labels,num_steps=300000,learning_rate=5e-5,add_intercept=True)\n",
    "print(wights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

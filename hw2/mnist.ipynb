{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2629,
     "status": "ok",
     "timestamp": 1556855652236,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "eWoHtt5X0Qs_",
    "outputId": "f46bd4e5-2cce-4cab-ce0e-46b932d9b969",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testJ/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testJ/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcuda.so.1: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-68d892e66f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/tom/anaconda3/envs/testJ/lib/python3.7/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "# load required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load required functionality from keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as keras_backend\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngzN9HbX0QtG"
   },
   "source": [
    "## MNIST Dataset\n",
    "The MNIST data set is a large database of handwritten digits (0-9) that is commonly used for training and benchmarking binary classification models.\n",
    "\n",
    "Before we create any models, we'll start by loading the MNIST data and viewing some sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1556855669571,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "B_BlV7do0QtH",
    "outputId": "f72529d5-247d-4822-dbb2-5b9ca2cee9d4"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# split MNIST data into training and testing sets\n",
    "# - training: data used to learn the model parameters\n",
    "# - testing: a separate set that we will use to validate our model performance\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#http://yann.lecun.com/exdb/mnist/ 資料來源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1556855679201,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "ZFoAr7kV0QtN",
    "outputId": "d6b218e1-fab5-4935-afc5-9641058846fc"
   },
   "outputs": [],
   "source": [
    "# check the dimensions of the data\n",
    "print( X_train.shape ) # 60000筆 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 694,
     "status": "ok",
     "timestamp": 1556855703869,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "POw937pI0QtS",
    "outputId": "cff9e2f5-df09-40bb-be02-029498930397"
   },
   "outputs": [],
   "source": [
    "# select an image\n",
    "img = X_train[0]\n",
    "\n",
    "# show the image\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RbQ09ace0QtW"
   },
   "source": [
    "Notice anything about the images? For example, how many pixels are in each image?\n",
    "    每張圖都是 28*28，但實際數字的大小好像不到 28*28。反而像 20*20 置中有黑色的邊框\n",
    "    \n",
    "Now that we can view the images, let's try also showing the true label alongside the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1556855746563,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "TRi_sEYl0QtX",
    "outputId": "7ac3f94f-0f51-4930-b708-4111cd5f1ea7"
   },
   "outputs": [],
   "source": [
    "# select one of the images and its corresponding label\n",
    "i = 403\n",
    "img = X_train[i]\n",
    "label = y_train[i]\n",
    "\n",
    "# show the image and its label\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"True label: %d\" % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0c0P6d2S30Q6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RlbCQU880Qtb"
   },
   "source": [
    "**Logistic regression implemented in Keras**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsr2bf9D0Qtc"
   },
   "source": [
    "Before moving onto models, we should pre-process the MNIST data:\n",
    "1. reshape the MNIST images into 1D arrays (from 2D arrays)\n",
    "2. normalize the MNIST images\n",
    "3. convert the MNIST labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3V2ifxq0Qtd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# reshape the data: (n_samples, 28, 28) => (n_samples, 28*28)\n",
    "X_train = X_train.reshape(-1, 28 * 28)\n",
    "X_test = X_test.reshape(-1, 28 * 28)\n",
    "\n",
    "# convert data type and normalize the values (8-bit = 256 = 0...255)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# convert the class labels to 10-dimensional class arrays:\n",
    "# 這邊就是上課說到 0~9 有大小差別的問題，所以轉成 bag of words\n",
    "# - before: y_train = (n_samples, )\n",
    "# - after: Y_train = (n_samples, 10)\n",
    "#\n",
    "Y_train = np_utils.to_categorical(y_train, 10)# keras 用 numpy 寫成的 function \n",
    "Y_test = np_utils.to_categorical(y_test, 10)# 詳情看 https://keras.io/utils/\n",
    "\n",
    "#y_Train = np.eye(10)[y_train] #這樣寫有同樣的效果 identity matrix 第 y_train row\n",
    "#print(y_Train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 694,
     "status": "ok",
     "timestamp": 1556856059689,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "6K0IQpBy2dEk",
    "outputId": "314d6dee-83d1-455f-e1a9-acd1f775e367"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(y_train[0], Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20677,
     "status": "ok",
     "timestamp": 1556856287187,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "mNF81u_h0Qtg",
    "outputId": "78f60761-d8b0-4dc8-eebf-59a23aa1dc32"
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=28*28, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "#model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer='sgd',\n",
    "#              metrics=['accuracy'])            \n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])            \n",
    "\n",
    "\n",
    "# train the model on data\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=128, # how many images to look at together\n",
    "          nb_epoch=20,       # how many epochs to run before stopping\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test)\n",
    "         )\n",
    "\n",
    "# test the trained model on the testing set\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "\n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1556841196972,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "62uUbq530Qtm",
    "outputId": "78b71840-df89-407a-bfa6-c4f2a0dd20bd"
   },
   "outputs": [],
   "source": [
    "# select an image\n",
    "i = 200\n",
    "img = X_test[i].reshape(28, 28)\n",
    "\n",
    "# prepare the image to be used in the model\n",
    "x = img.reshape(-1, 28*28)\n",
    "\n",
    "# get the model output\n",
    "model_label = np.argmax( model.predict(x) )\n",
    "\n",
    "# get the true label\n",
    "true_label = np.argmax(Y_test[i])\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('True label: {0}, Model label: {1}'.format(true_label, model_label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1MQC55ZQ0Qto"
   },
   "source": [
    "**Multilayer Perceptron (MLP)**\n",
    "\n",
    "Next we'll try out a \"classic\" neural network model (i.e. not a deep neural network).\n",
    "\n",
    "A Multilayer Perceptron (aka an Artificial Neural Network) is made up of an input layer, one or more hidden layers, and an output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9hqBLv70Qts"
   },
   "outputs": [],
   "source": [
    "# create the MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# print a summary of the model topology\n",
    "#model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfjucLyT0Qtu"
   },
   "source": [
    "**Discussion**\n",
    "**Question 1:** How did the accuracy of the MLP model compare to the Logistic Regression model?\n",
    "\n",
    "**Question 2:** Can you identify any other differences between the MLP and Logistic Regression models? *Hint:* Was there a difference in the code complexity and/or training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZCtCleCi0Qtw"
   },
   "source": [
    "**Convolutional Neural Network (CNN)**\n",
    "Now let's try out first deep neural network: a Convolutional Neural Network (CNN).\n",
    "\n",
    "The CNN is made up of a few core layer types, which get stacked on top of each other:\n",
    "- convolutional layers (2D)\n",
    "- max pooling layers (2D)\n",
    "- fully connected (aka densely connected) layers (same type as in the MLP model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0knPgk1k0Qtw"
   },
   "source": [
    "First, we need to perform pre-processing on the MNIST data, but with a slight tweak from the previous examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bU9311av0Qtx"
   },
   "outputs": [],
   "source": [
    "# load the data again (to be safe)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the data based on what backend is in use (TensorFlow or Thean)\n",
    "if keras_backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "    X_test = X_test.reshape(-1, 1, 28, 28)\n",
    "else:\n",
    "    X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "    X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# convert data type and normalize the values (8-bit = 256 = 0...255)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# convert the class labels to 10-dimensional class arrays:\n",
    "# - before: y_train = (n_samples, )\n",
    "# - after: Y_train = (n_samples, 10)\n",
    "#\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pRy3MhF0Qt0"
   },
   "outputs": [],
   "source": [
    "# create the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)\n",
    "                ))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "3FVOAray0Qt2"
   },
   "source": [
    "**Discussion**\n",
    "**Question 1:** How did the accuracy of the CNN compare to the MLP and Logistic Regression models?\n",
    "\n",
    "**Question 2:** Can you identify any other differences between the three models?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_mnist.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

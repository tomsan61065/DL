{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9747801240775790832\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2668979052289921627\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio # python 讀取 .mat file\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as keras_backend\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()) #check available device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['setosa'], dtype='<U6')] [5.1 3.5 1.4 0.2]\n"
     ]
    }
   ],
   "source": [
    "matData = sio.loadmat(\"fisheriris.mat\") # 鳶尾花\n",
    "#print(matData.items()) # 得知有哪些 items \n",
    "\n",
    "# iris(species, meas),(3 label, 4 attribute) 150 筆\n",
    "irisSpecies = np.array(matData[\"species\"]) # type(setosa, versicolor, virginica)\n",
    "irisMeas = np.array(matData[\"meas\"]) # sepal(花萼)長、寬, petal(花瓣)長、寬 cm\n",
    "print(irisSpecies[0], irisMeas[0])\n",
    "# MAT 格式問題，array[array(), array(), ...]\n",
    "#print(irisSpecies[:, 0], irisMeas[0]) 各種 fail\n",
    "#print([item[0][0] for item in irisSpecies])\n",
    "irisSpecies = [item[0][0] for item in irisSpecies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.       0.       0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708\n",
      "  1.       0.0376   0.85243 -0.17755  0.59755 -0.44945  0.60536 -0.38223\n",
      "  0.84356 -0.38542  0.58212 -0.32192  0.56971 -0.29674  0.36946 -0.47357\n",
      "  0.56811 -0.51171  0.41078 -0.46168  0.21266 -0.3409   0.42267 -0.54487\n",
      "  0.18641 -0.453  ] [array(['g'], dtype='<U1')]\n"
     ]
    }
   ],
   "source": [
    "matData = sio.loadmat(\"ionosphere.mat\") # 電離層\n",
    "#print(matData.items())\n",
    "\n",
    "# (X, Y),(34 attribute, 2 label) 351 筆\n",
    "ionosphereX = np.array(matData[\"X\"])\n",
    "ionosphereY = np.array(matData[\"Y\"])\n",
    "print(ionosphereX[0], ionosphereY[0])\n",
    "ionosphereY = [item[0][0] for item in ionosphereY]\n",
    "#print(ionosphereY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== iris ==\n",
      "(120, 4)\n",
      "(30, 4)\n",
      "== ionosphere ==\n",
      "(280, 34)\n",
      "(71, 34)\n"
     ]
    }
   ],
   "source": [
    "# split data into (train, test) = (80%, 20%)\n",
    "irisSpecies_train, irisSpecies_test, irisMeas_train, irisMeas_test = train_test_split(irisSpecies, irisMeas, test_size=0.2)\n",
    "print(\"== iris ==\")\n",
    "print(irisMeas_train.shape)\n",
    "print(irisMeas_test.shape)\n",
    "#print(irisSpecies_train)\n",
    "\n",
    "ionosphereX_train, ionosphereX_test, ionosphereY_train, ionosphereY_test = train_test_split(ionosphereX, ionosphereY, test_size=0.2)\n",
    "print(\"== ionosphere ==\")\n",
    "print(ionosphereX_train.shape)\n",
    "print(ionosphereX_test.shape)\n",
    "#print(ionosphereY_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=10000.0, multi_class='multinomial',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "== iris ==\n",
      "iris train accurracy: 0.966667 %\n",
      "iris test accurracy: 0.966667 %\n",
      "\n",
      "== ionosphere ==\n",
      "ionosphere accurracy: 0.925000 %\n",
      "ionosphere accurracy: 0.887324 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Logistic Regression\n",
    "\"\"\"\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1e4)\n",
    "print(logreg)\n",
    "\n",
    "logreg.fit(irisMeas_train, irisSpecies_train)\n",
    "predictIrisTrain = logreg.predict(irisMeas_train)\n",
    "count = 0\n",
    "for i in range(len(predictIrisTrain)):\n",
    "    if predictIrisTrain[i] == irisSpecies_train[i]:\n",
    "        count += 1\n",
    "print(\"\\n== iris ==\")\n",
    "print(\"iris train accurracy: %f %%\" % ( count/len(predictIrisTrain) ) )\n",
    "predictIris = logreg.predict(irisMeas_test)\n",
    "count = 0\n",
    "for i in range(len(predictIris)):\n",
    "    if predictIris[i] == irisSpecies_test[i]:\n",
    "        count += 1\n",
    "print(\"iris test accurracy: %f %%\" % ( count/len(predictIris) ) )\n",
    "\n",
    "\n",
    "logreg.fit(ionosphereX_train, ionosphereY_train)\n",
    "predictIonosphereTrain = logreg.predict(ionosphereX_train)\n",
    "count = 0\n",
    "for i in range(len(predictIonosphereTrain)):\n",
    "    if predictIonosphereTrain[i] == ionosphereY_train[i]:\n",
    "        count += 1\n",
    "print(\"\\n== ionosphere ==\")\n",
    "print(\"ionosphere accurracy: %f %%\" % ( count/len(predictIonosphereTrain) ) )\n",
    "predictIonosphere = logreg.predict(ionosphereX_test)\n",
    "count = 0\n",
    "for i in range(len(predictIonosphere)):\n",
    "    if predictIonosphere[i] == ionosphereY_test[i]:\n",
    "        count += 1\n",
    "print(\"ionosphere accurracy: %f %%\" % ( count/len(predictIonosphere) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nirisSpecies_train\\nirisSpecies_test\\nirisMeas_train\\nirisMeas_tes\\n\\n\\nionosphereX_train\\nionosphereX_test\\nionosphereY_train\\nionosphereY_test\\n'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Neural Network\n",
    "\"\"\"\n",
    "\n",
    "#preprocessing data, turn label string -> vector\n",
    "for i in range(len(irisSpecies_train)):\n",
    "    if irisSpecies_train[i] == \"setosa\":\n",
    "        irisSpecies_train[i] = 0\n",
    "    elif irisSpecies_train[i] == \"versicolor\":\n",
    "        irisSpecies_train[i] = 0\n",
    "    else:\n",
    "        irisSpecies_train[i] = 2\n",
    "irisSpecies_train = np_utils.to_categorical(irisSpecies_train, 3)\n",
    "for i in range(len(irisSpecies_test)):\n",
    "    if irisSpecies_test[i] == \"setosa\":\n",
    "        irisSpecies_test[i] = 0\n",
    "    elif irisSpecies_test[i] == \"versicolor\":\n",
    "        irisSpecies_test[i] = 0\n",
    "    else:\n",
    "        irisSpecies_test[i] = 2\n",
    "irisSpecies_test = np_utils.to_categorical(irisSpecies_test, 3)\n",
    "\n",
    "#print(ionosphereY_train)\n",
    "for i in range(len(ionosphereY_train)):\n",
    "    if ionosphereY_train[i] == \"g\":\n",
    "        ionosphereY_train[i] = 0\n",
    "    else:\n",
    "        ionosphereY_train[i] = 1\n",
    "ionosphereY_train = np_utils.to_categorical(ionosphereY_train, 2)\n",
    "for i in range(len(ionosphereY_test)):\n",
    "    if ionosphereY_test[i] == \"g\":\n",
    "        ionosphereY_test[i] = 0\n",
    "    else:\n",
    "        ionosphereY_test[i] = 1\n",
    "ionosphereY_test = np_utils.to_categorical(ionosphereY_test, 2)\n",
    "#print(ionosphereY_train)\n",
    "\"\"\"\n",
    "irisSpecies_train\n",
    "irisSpecies_test\n",
    "irisMeas_train\n",
    "irisMeas_tes\n",
    "\n",
    "\n",
    "ionosphereX_train\n",
    "ionosphereX_test\n",
    "ionosphereY_train\n",
    "ionosphereY_test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 1.0233 - acc: 0.4000 - val_loss: 0.7237 - val_acc: 0.9333\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6483 - acc: 0.7417 - val_loss: 0.5510 - val_acc: 0.7000\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.6444 - acc: 0.6500 - val_loss: 0.4479 - val_acc: 0.7000\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.5210 - acc: 0.7250 - val_loss: 0.3486 - val_acc: 0.8000\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.3921 - acc: 0.8250 - val_loss: 0.3151 - val_acc: 0.7667\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.4361 - acc: 0.7833 - val_loss: 0.2431 - val_acc: 0.9667\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.4025 - acc: 0.8333 - val_loss: 0.2104 - val_acc: 0.9333\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.2983 - acc: 0.8833 - val_loss: 0.1754 - val_acc: 0.9333\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.2977 - acc: 0.8667 - val_loss: 0.1591 - val_acc: 0.9333\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.2948 - acc: 0.8500 - val_loss: 0.1632 - val_acc: 0.9333\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.2469 - acc: 0.8917 - val_loss: 0.2070 - val_acc: 0.9000\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.2704 - acc: 0.9083 - val_loss: 0.1556 - val_acc: 0.9333\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.2397 - acc: 0.9167 - val_loss: 0.1377 - val_acc: 0.9333\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2146 - acc: 0.9250 - val_loss: 0.0931 - val_acc: 0.9333\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.1788 - acc: 0.9333 - val_loss: 0.1150 - val_acc: 0.9333\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.1968 - acc: 0.9167 - val_loss: 0.1060 - val_acc: 0.9333\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.1636 - acc: 0.9417 - val_loss: 0.0958 - val_acc: 0.9333\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.1201 - acc: 0.9583 - val_loss: 0.1371 - val_acc: 0.9333\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.1881 - acc: 0.9333 - val_loss: 0.0714 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.1380 - acc: 0.9417 - val_loss: 0.0554 - val_acc: 1.0000\n",
      "\n",
      "== Iris ==\n",
      "Train loss: 0.07053684704005718\n",
      "Train accuracy: 0.975\n",
      "Test loss: 0.05536802485585213\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Dense -> fully connected, (node num, input size, activation function)\n",
    "model.add(Dense(32, input_dim=4, activation='relu'))\n",
    "#input_shape=(784,) 等價於 input_dim=784 ，接收 n 個 784 input\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "# compile the model\n",
    "#model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer='sgd',\n",
    "#              metrics=['accuracy'])            \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])            \n",
    "\n",
    "\n",
    "# train the model on data\n",
    "model.fit(irisMeas_train, irisSpecies_train,\n",
    "          batch_size=1, # how many data to look at together\n",
    "          epochs=20,    # how many epochs to run before stopping\n",
    "          verbose=2,  # 訓練的詳細資料, 0=安靜, 1=進度條, 2=每輪一行\n",
    "          validation_data=(irisMeas_test, irisSpecies_test)\n",
    "         )\n",
    "\n",
    "# test the trained model on the testing set\n",
    "score = model.evaluate(irisMeas_train, irisSpecies_train, verbose=0) \n",
    "print(\"\\n== Iris ==\")\n",
    "print('Train loss:', score[0]) #loss\n",
    "print('Train accuracy:', score[1])\n",
    "score = model.evaluate(irisMeas_test, irisSpecies_test, verbose=0) \n",
    "\n",
    "print('Test loss:', score[0]) #loss\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280 samples, validate on 71 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 0.5433 - acc: 0.7250 - val_loss: 0.3326 - val_acc: 0.8873\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.3277 - acc: 0.9071 - val_loss: 0.2303 - val_acc: 0.9155\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.2115 - acc: 0.9286 - val_loss: 0.1300 - val_acc: 0.9577\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.1543 - acc: 0.9500 - val_loss: 0.1103 - val_acc: 0.9437\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.1610 - acc: 0.9500 - val_loss: 0.1597 - val_acc: 0.9296\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.1628 - acc: 0.9607 - val_loss: 0.1334 - val_acc: 0.9296\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.1240 - acc: 0.9750 - val_loss: 0.1475 - val_acc: 0.9577\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.0831 - acc: 0.9750 - val_loss: 0.2008 - val_acc: 0.9155\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.0738 - acc: 0.9714 - val_loss: 0.2605 - val_acc: 0.9155\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.1047 - acc: 0.9714 - val_loss: 0.1396 - val_acc: 0.9155\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.0801 - acc: 0.9786 - val_loss: 0.1240 - val_acc: 0.9296\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.1126 - acc: 0.9679 - val_loss: 0.1402 - val_acc: 0.9296\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.0765 - acc: 0.9786 - val_loss: 0.1171 - val_acc: 0.9437\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.0815 - acc: 0.9714 - val_loss: 0.2358 - val_acc: 0.9437\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.0771 - acc: 0.9750 - val_loss: 0.1114 - val_acc: 0.9577\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.0707 - acc: 0.9750 - val_loss: 0.2259 - val_acc: 0.9155\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.0550 - acc: 0.9857 - val_loss: 0.1049 - val_acc: 0.9296\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.0629 - acc: 0.9786 - val_loss: 0.1043 - val_acc: 0.9437\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.0367 - acc: 0.9929 - val_loss: 0.0661 - val_acc: 0.9859\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.0562 - acc: 0.9821 - val_loss: 0.2101 - val_acc: 0.9155\n",
      "\n",
      "== ionosphere ==\n",
      "Train loss: 0.030319906638136933\n",
      "Train accuracy: 0.9892857142857143\n",
      "Test loss: 0.21008990516125317\n",
      "Test accuracy: 0.9154929585859809\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model2 = Sequential()\n",
    "\n",
    "# Dense -> fully connected, (node num, input size, activation function)\n",
    "model2.add(Dense(64, input_dim=34, activation='relu'))\n",
    "#input_shape=(784,) 等價於 input_dim=784 ，接收 n 個 784 input\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# compile the model\n",
    "#model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer='sgd',\n",
    "#              metrics=['accuracy'])            \n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])            \n",
    "\n",
    "\n",
    "# train the model on data\n",
    "model2.fit(ionosphereX_train, ionosphereY_train,\n",
    "          batch_size=1, # how many data to look at together\n",
    "          epochs=20,    # how many epochs to run before stopping\n",
    "          verbose=2,  # 訓練的詳細資料, 0=安靜, 1=進度條, 2=每輪一行\n",
    "          validation_data=(ionosphereX_test, ionosphereY_test)\n",
    "         )\n",
    "\n",
    "# test the trained model on the testing set\n",
    "score = model2.evaluate(ionosphereX_train, ionosphereY_train, verbose=0) \n",
    "print(\"\\n== ionosphere ==\")\n",
    "print('Train loss:', score[0]) #loss\n",
    "print('Train accuracy:', score[1])\n",
    "score = model2.evaluate(ionosphereX_test, ionosphereY_test, verbose=0) \n",
    "\n",
    "print('Test loss:', score[0]) #loss\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

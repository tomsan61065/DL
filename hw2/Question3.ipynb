{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2629,
     "status": "ok",
     "timestamp": 1556855652236,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "eWoHtt5X0Qs_",
    "outputId": "f46bd4e5-2cce-4cab-ce0e-46b932d9b969",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5368198558317355868\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8369810307203559952\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# load required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load required functionality from keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adadelta, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as keras_backend\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZCtCleCi0Qtw"
   },
   "source": [
    "**Convolutional Neural Network (CNN)**\n",
    "Now let's try out first deep neural network: a Convolutional Neural Network (CNN).\n",
    "\n",
    "The CNN is made up of a few core layer types, which get stacked on top of each other:\n",
    "- convolutional layers (2D)\n",
    "- max pooling layers (2D)\n",
    "- fully connected (aka densely connected) layers (same type as in the MLP model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0knPgk1k0Qtw"
   },
   "source": [
    "First, we need to perform pre-processing on the MNIST data, but with a slight tweak from the previous examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the data again (to be safe)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\"\"\"\n",
    "    Adding noise to image\n",
    "\"\"\"\n",
    "import random \n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# 10%, 20%, 40%\n",
    "img_size = 28*28\n",
    "\n",
    "X_train_10 = np.zeros((60000, 28*28))\n",
    "X_test_10 = np.zeros((10000, 28*28))\n",
    "X_train_20 = np.zeros((60000, 28*28))\n",
    "X_test_20 = np.zeros((10000, 28*28))\n",
    "X_train_40 = np.zeros((60000, 28*28))\n",
    "X_test_40 = np.zeros((10000, 28*28))\n",
    "\n",
    "for i in range(len(X_train)): \n",
    "    ran_seq = random.sample([n for n in range(img_size)], np.int(img_size* 0.1)) \n",
    "    ran_seq2 = random.sample([n for n in range(img_size)], np.int(img_size* 0.2)) \n",
    "    ran_seq3 = random.sample([n for n in range(img_size)], np.int(img_size* 0.4)) \n",
    "    X_train_10[i] = X_train[i].reshape(-1, img_size) \n",
    "    X_train_20[i] = np.copy(X_train_10[i])\n",
    "    X_train_40[i] = np.copy(X_train_10[i])\n",
    "    X_train_10[i, ran_seq] = 255\n",
    "    X_train_20[i, ran_seq2] = 255\n",
    "    X_train_40[i, ran_seq3] = 255\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    ran_seq = random.sample([n for n in range(img_size)], np.int(img_size* 0.1)) \n",
    "    ran_seq2 = random.sample([n for n in range(img_size)], np.int(img_size* 0.2)) \n",
    "    ran_seq3 = random.sample([n for n in range(img_size)], np.int(img_size* 0.4)) \n",
    "    X_test_10[i] = X_test[i].reshape(-1, img_size) \n",
    "    X_test_20[i] = np.copy(X_test_10[i])\n",
    "    X_test_40[i] = np.copy(X_test_10[i])\n",
    "    X_test_10[i, ran_seq] = 255\n",
    "    X_test_20[i, ran_seq2] = 255\n",
    "    X_test_40[i, ran_seq3] = 255\n",
    "    \n",
    "print(X_train_10.shape)\n",
    "#print(x[1])\n",
    "\n",
    "img = X_train_10[1].reshape(28, 28)\n",
    "label = y_train[1]\n",
    "\n",
    "# show the image and its label\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"True label: %d\" % label)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bU9311av0Qtx",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reshape the data based on what backend is in use (TensorFlow or Thean)\n",
    "if keras_backend.image_data_format() == 'channels_first': #Thean\n",
    "    X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "    X_test = X_test.reshape(-1, 1, 28, 28)\n",
    "else: # TensorFlow\n",
    "    X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "    X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "    X_train_10 = X_train_10.reshape(-1, 28, 28, 1)\n",
    "    X_train_20 = X_train_20.reshape(-1, 28, 28, 1)\n",
    "    X_train_40 = X_train_40.reshape(-1, 28, 28, 1)\n",
    "    X_test_10 = X_test_10.reshape(-1, 28, 28, 1)\n",
    "    X_test_20 = X_test_20.reshape(-1, 28, 28, 1)\n",
    "    X_test_40 = X_test_40.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "img = X_train[1, :, :, 0]\n",
    "label = y_train[1]\n",
    "\n",
    "# show the image and its label\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"True label: %d\" % label)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# convert data type and normalize the values (8-bit = 256 = 0...255)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "X_train_10 = X_train_10.astype('float32') / 255\n",
    "X_train_20 = X_train_20.astype('float32') / 255\n",
    "X_train_40 = X_train_40.astype('float32') / 255\n",
    "X_test_10 = X_test_10.astype('float32') / 255\n",
    "X_test_20 = X_test_20.astype('float32') / 255\n",
    "X_test_40 = X_test_40.astype('float32') / 255\n",
    "\n",
    "# convert the class labels to 10-dimensional class arrays:\n",
    "# - before: y_train = (n_samples, )\n",
    "# - after: Y_train = (n_samples, 10)\n",
    "#\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pRy3MhF0Qt0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "=================================================================\n",
      "Total params: 131,329\n",
      "Trainable params: 130,753\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 439s 7ms/step - loss: 0.0574 - acc: 0.8017 - val_loss: 0.0255 - val_acc: 0.8125\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 440s 7ms/step - loss: 0.0237 - acc: 0.8140 - val_loss: 0.0164 - val_acc: 0.8134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"== 10% ==\")\\nmodel.fit(X_train_10, Y_train,\\n          batch_size=128,\\n          epochs=2,\\n          verbose=1,\\n          validation_data=(X_test_10, Y_test))\\n\\nscore = model.evaluate(X_test_10, Y_test, verbose=0)\\n\\nprint(\\'Test loss:\\', score[0])\\nprint(\\'Test accuracy:\\', score[1])\\n\\n\\nprint(\"== 20% ==\")\\nmodel.fit(X_train_20, Y_train,\\n          batch_size=128,\\n          epochs=2,\\n          verbose=1,\\n          validation_data=(X_test_20, Y_test))\\n\\nscore = model.evaluate(X_test_20, Y_test, verbose=0)\\n\\nprint(\\'Test loss:\\', score[0])\\nprint(\\'Test accuracy:\\', score[1])\\n\\n\\nprint(\"== 40% ==\")\\nmodel.fit(X_train_40, Y_train,\\n          batch_size=128,\\n          epochs=2,\\n          verbose=1,\\n          validation_data=(X_test_40, Y_test))\\n\\nscore = model.evaluate(X_test_40, Y_test, verbose=0)\\n\\nprint(\\'Test loss:\\', score[0])\\nprint(\\'Test accuracy:\\', score[1])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1),\n",
    "                 padding=\"same\"\n",
    "                ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(1, (3, 3), activation='relu', padding=\"same\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_40, X_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_40, X_test))\n",
    "\n",
    "\"\"\"\n",
    "print(\"== 10% ==\")\n",
    "model.fit(X_train_10, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_10, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test_10, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print(\"== 20% ==\")\n",
    "model.fit(X_train_20, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_20, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test_20, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print(\"== 40% ==\")\n",
    "model.fit(X_train_40, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_40, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test_40, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Noise remove accuracy ==\n",
      "Train loss: 0.016546125790973504\n",
      "Train accuracy: 0.8143690053939819\n",
      "Test loss: 0.01638315934240818\n",
      "Test accuracy: 0.8134149232864379\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"== Noise remove accuracy ==\")\n",
    "score = model.evaluate(X_train_40, X_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "score = model.evaluate(X_test_40, X_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "X_train_10_removeNoise = model.predict(X_train_10)\n",
    "X_train_20_removeNoise = model.predict(X_train_20)\n",
    "X_train_40_removeNoise = model.predict(X_train_40)\n",
    "X_test_10_removeNoise = model.predict(X_test_10)\n",
    "X_test_20_removeNoise = model.predict(X_test_20)\n",
    "X_test_40_removeNoise = model.predict(X_test_40)\n",
    "\n",
    "\n",
    "img = X_train_40_removeNoise[1, :, :, 0]\n",
    "label = y_train[1]\n",
    "\n",
    "# show the image and its label\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"True label: %d\" % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 10% with remove noise ==\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 46s 769us/step - loss: 0.2735 - acc: 0.9151 - val_loss: 0.0699 - val_acc: 0.9781\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 47s 778us/step - loss: 0.0922 - acc: 0.9733 - val_loss: 0.0437 - val_acc: 0.9860\n",
      "Test loss: 0.04371540787173435\n",
      "Test accuracy: 0.986\n",
      "== 20% with remove noise ==\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 45s 749us/step - loss: 0.0700 - acc: 0.9794 - val_loss: 0.0408 - val_acc: 0.9860\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 45s 743us/step - loss: 0.0586 - acc: 0.9828 - val_loss: 0.0371 - val_acc: 0.9881\n",
      "Test loss: 0.037110773968260034\n",
      "Test accuracy: 0.9881\n",
      "== 40% with remove noise ==\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 45s 756us/step - loss: 0.0629 - acc: 0.9810 - val_loss: 0.0438 - val_acc: 0.9860\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 44s 740us/step - loss: 0.0586 - acc: 0.9824 - val_loss: 0.0461 - val_acc: 0.9854\n",
      "Test loss: 0.04607821190490795\n",
      "Test accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "# create the CNN model\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)\n",
    "                ))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"== 10% with remove noise ==\")\n",
    "model2.fit(X_train_10_removeNoise, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_10_removeNoise, Y_test))\n",
    "\n",
    "score = model2.evaluate(X_test_10_removeNoise, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print(\"== 20% with remove noise ==\")\n",
    "model2.fit(X_train_20_removeNoise, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_20_removeNoise, Y_test))\n",
    "\n",
    "score = model2.evaluate(X_test_20_removeNoise, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print(\"== 40% with remove noise ==\")\n",
    "model2.fit(X_train_40_removeNoise, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_40_removeNoise, Y_test))\n",
    "\n",
    "score = model2.evaluate(X_test_40_removeNoise, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_mnist.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

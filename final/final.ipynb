{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2629,
     "status": "ok",
     "timestamp": 1556855652236,
     "user": {
      "displayName": "Jerry Peng",
      "photoUrl": "https://lh5.googleusercontent.com/-X5dmdw86Bpo/AAAAAAAAAAI/AAAAAAAAAEc/gx43BV5vrGs/s64/photo.jpg",
      "userId": "10707771670913494566"
     },
     "user_tz": -480
    },
    "id": "eWoHtt5X0Qs_",
    "outputId": "f46bd4e5-2cce-4cab-ce0e-46b932d9b969",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16998723289697034760\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6700198133\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6661489754043158607\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load required functionality from keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adadelta, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as keras_backend\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "keras_backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZCtCleCi0Qtw"
   },
   "source": [
    "**Convolutional Neural Network (CNN)**\n",
    "Now let's try out first deep neural network: a Convolutional Neural Network (CNN).\n",
    "\n",
    "The CNN is made up of a few core layer types, which get stacked on top of each other:\n",
    "- convolutional layers (2D)\n",
    "- max pooling layers (2D)\n",
    "- fully connected (aka densely connected) layers (same type as in the MLP model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0knPgk1k0Qtw"
   },
   "source": [
    "First, we need to perform pre-processing on the MNIST data, but with a slight tweak from the previous examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 4s 0us/step\n",
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the data again (to be safe)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\"\"\"\n",
    "    Adding noise to image\n",
    "\"\"\"\n",
    "import random \n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# 10%, 20%, 40%\n",
    "img_size = 28*28\n",
    "\n",
    "X_train_10 = np.zeros((60000, 28*28))\n",
    "X_test_10 = np.zeros((10000, 28*28))\n",
    "X_train_20 = np.zeros((60000, 28*28))\n",
    "X_test_20 = np.zeros((10000, 28*28))\n",
    "X_train_40 = np.zeros((60000, 28*28))\n",
    "X_test_40 = np.zeros((10000, 28*28))\n",
    "\n",
    "for i in range(len(X_train)): \n",
    "    ran_seq = random.sample([n for n in range(img_size)], np.int(img_size* 0.1)) \n",
    "    ran_seq2 = random.sample([n for n in range(img_size)], np.int(img_size* 0.2)) \n",
    "    ran_seq3 = random.sample([n for n in range(img_size)], np.int(img_size* 0.4)) \n",
    "    X_train_10[i] = X_train[i].reshape(-1, img_size) \n",
    "    X_train_20[i] = np.copy(X_train_10[i])\n",
    "    X_train_40[i] = np.copy(X_train_10[i])\n",
    "    X_train_10[i, ran_seq] = 255\n",
    "    X_train_20[i, ran_seq2] = 255\n",
    "    X_train_40[i, ran_seq3] = 255\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    ran_seq = random.sample([n for n in range(img_size)], np.int(img_size* 0.1)) \n",
    "    ran_seq2 = random.sample([n for n in range(img_size)], np.int(img_size* 0.2)) \n",
    "    ran_seq3 = random.sample([n for n in range(img_size)], np.int(img_size* 0.4)) \n",
    "    X_test_10[i] = X_test[i].reshape(-1, img_size) \n",
    "    X_test_20[i] = np.copy(X_test_10[i])\n",
    "    X_test_40[i] = np.copy(X_test_10[i])\n",
    "    X_test_10[i, ran_seq] = 255\n",
    "    X_test_20[i, ran_seq2] = 255\n",
    "    X_test_40[i, ran_seq3] = 255\n",
    "    \n",
    "print(X_train_10.shape)\n",
    "#print(x[1])\n",
    "\n",
    "img = X_train_10[1].reshape(28, 28)\n",
    "label = y_train[1]\n",
    "\n",
    "# show the image and its label\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"True label: %d\" % label)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bU9311av0Qtx",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reshape the data based on what backend is in use (TensorFlow or Thean)\n",
    "if keras_backend.image_data_format() == 'channels_first': #Thean\n",
    "    X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "    X_test = X_test.reshape(-1, 1, 28, 28)\n",
    "else: # TensorFlow\n",
    "    X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "    X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "    X_train_10 = X_train_10.reshape(-1, 28, 28, 1)\n",
    "    X_train_20 = X_train_20.reshape(-1, 28, 28, 1)\n",
    "    X_train_40 = X_train_40.reshape(-1, 28, 28, 1)\n",
    "    X_test_10 = X_test_10.reshape(-1, 28, 28, 1)\n",
    "    X_test_20 = X_test_20.reshape(-1, 28, 28, 1)\n",
    "    X_test_40 = X_test_40.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "img = X_train[1, :, :, 0]\n",
    "label = y_train[1]\n",
    "\n",
    "# show the image and its label\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"True label: %d\" % label)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# convert data type and normalize the values (8-bit = 256 = 0...255)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "X_train_10 = X_train_10.astype('float32') / 255\n",
    "X_train_20 = X_train_20.astype('float32') / 255\n",
    "X_train_40 = X_train_40.astype('float32') / 255\n",
    "X_test_10 = X_test_10.astype('float32') / 255\n",
    "X_test_20 = X_test_20.astype('float32') / 255\n",
    "X_test_40 = X_test_40.astype('float32') / 255\n",
    "\n",
    "# convert the class labels to 10-dimensional class arrays:\n",
    "# - before: y_train = (n_samples, )\n",
    "# - after: Y_train = (n_samples, 10)\n",
    "#\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pRy3MhF0Qt0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asus\\Miniconda3\\envs\\testJ\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\asus\\Miniconda3\\envs\\testJ\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "=================================================================\n",
      "Total params: 131,329\n",
      "Trainable params: 130,753\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\asus\\Miniconda3\\envs\\testJ\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0563 - acc: 0.8026 - val_loss: 0.0235 - val_acc: 0.8119\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 29s 482us/step - loss: 0.0239 - acc: 0.8140 - val_loss: 0.0197 - val_acc: 0.8134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"== 10% ==\")\\nmodel.fit(X_train_10, Y_train,\\n          batch_size=128,\\n          epochs=2,\\n          verbose=1,\\n          validation_data=(X_test_10, Y_test))\\n\\nscore = model.evaluate(X_test_10, Y_test, verbose=0)\\n\\nprint(\\'Test loss:\\', score[0])\\nprint(\\'Test accuracy:\\', score[1])\\n\\n\\nprint(\"== 20% ==\")\\nmodel.fit(X_train_20, Y_train,\\n          batch_size=128,\\n          epochs=2,\\n          verbose=1,\\n          validation_data=(X_test_20, Y_test))\\n\\nscore = model.evaluate(X_test_20, Y_test, verbose=0)\\n\\nprint(\\'Test loss:\\', score[0])\\nprint(\\'Test accuracy:\\', score[1])\\n\\n\\nprint(\"== 40% ==\")\\nmodel.fit(X_train_40, Y_train,\\n          batch_size=128,\\n          epochs=2,\\n          verbose=1,\\n          validation_data=(X_test_40, Y_test))\\n\\nscore = model.evaluate(X_test_40, Y_test, verbose=0)\\n\\nprint(\\'Test loss:\\', score[0])\\nprint(\\'Test accuracy:\\', score[1])\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1),\n",
    "                 padding=\"same\"\n",
    "                ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(1, (3, 3), activation='relu', padding=\"same\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_40, X_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_40, X_test))\n",
    "\n",
    "\"\"\"\n",
    "print(\"== 10% ==\")\n",
    "model.fit(X_train_10, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_10, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test_10, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print(\"== 20% ==\")\n",
    "model.fit(X_train_20, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_20, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test_20, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print(\"== 40% ==\")\n",
    "model.fit(X_train_40, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_40, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test_40, Y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Noise remove accuracy ==\n",
      "Train loss: 0.019753999929626783\n",
      "Train accuracy: 0.8143207702318828\n",
      "Test loss: 0.01973995618224144\n",
      "Test accuracy: 0.8133596942901611\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"== Noise remove accuracy ==\")\n",
    "score = model.evaluate(X_train_40, X_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "score = model.evaluate(X_test_40, X_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "X_train_10_removeNoise = model.predict(X_train_10)\n",
    "X_train_20_removeNoise = model.predict(X_train_20)\n",
    "X_train_40_removeNoise = model.predict(X_train_40)\n",
    "X_test_10_removeNoise = model.predict(X_test_10)\n",
    "X_test_20_removeNoise = model.predict(X_test_20)\n",
    "X_test_40_removeNoise = model.predict(X_test_40)\n",
    "\n",
    "\n",
    "img = X_train_40_removeNoise[1, :, :, 0]\n",
    "label = y_train[1]\n",
    "\n",
    "# show the image and its label\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"True label: %d\" % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 10% with remove noise ==\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.3321 - acc: 0.8981 - val_loss: 0.0916 - val_acc: 0.9708\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1334 - acc: 0.9591 - val_loss: 0.0724 - val_acc: 0.9767\n",
      "Test loss: 0.07240031437918078\n",
      "Test accuracy: 0.9767\n",
      "== 20% with remove noise ==\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0751 - acc: 0.9773 - val_loss: 0.0419 - val_acc: 0.9868\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0635 - acc: 0.9809 - val_loss: 0.0385 - val_acc: 0.9867\n",
      "Test loss: 0.03852416750941775\n",
      "Test accuracy: 0.9867\n",
      "== 40% with remove noise ==\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0624 - acc: 0.9818 - val_loss: 0.0411 - val_acc: 0.9862\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0548 - acc: 0.9832 - val_loss: 0.0415 - val_acc: 0.9872\n",
      "Test loss: 0.041496843585325405\n",
      "Test accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "# create the CNN model\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)\n",
    "                ))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"== 10% with remove noise ==\")\n",
    "model2.fit(X_train_10_removeNoise, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_10_removeNoise, Y_test))\n",
    "\n",
    "score = model2.evaluate(X_test_10_removeNoise, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print(\"== 20% with remove noise ==\")\n",
    "model2.fit(X_train_20_removeNoise, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_20_removeNoise, Y_test))\n",
    "\n",
    "score = model2.evaluate(X_test_20_removeNoise, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "print(\"== 40% with remove noise ==\")\n",
    "model2.fit(X_train_40_removeNoise, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_40_removeNoise, Y_test))\n",
    "\n",
    "score = model2.evaluate(X_test_40_removeNoise, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_mnist.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
